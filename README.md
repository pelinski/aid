# Advanced Interface Design Coursework repo
## Weekly challenges
+ **Challenge 1:** _Processing_. Simple modification to library example (Sound library).
+ **Challenge 2:** _Arduino_. Simultaneous piezo-speaker playing.
+ **Challenge 3:** _OSC control/Processing_. DrumMachine/sampler controlled via TouchOSC (phone).
+ **Challenge 4:** _RunwayML + Wekinator/OSC/Processing_. Face detection via RunwayML, extract lips contour, use as wekinator input for training a model for a FM synth.

![Slides](challenges/challenge4/images/slides.jpeg) 

## Final project
[Wekitunenator](https://github.com/gonski/wekitunenator) is an instrument that applies sound effects in real-time to the user's voice. These effects are selected with a MIDI controller and the parameters regulating them are modified with the user's hand movements. Machine learning is used in mapping hand movements to sound effects values. However, this instrument tries to move away from the conventional notion of machine learning (ML) as a control paradigm and intends to use ML as a discovery tool. This was inspired by Sonami and Fiebrink's paper [Reflections on Eight Years of Instrument Creation with Machine Learning](https://www.nime.org/proceedings/2020/nime2020_paper45.pdf), presented in NIME 2020.
